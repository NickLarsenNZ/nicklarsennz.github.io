[
{
	"uri": "https://nicklarsennz.github.io/posts/antlr/01-writing-a-parser-for-a-small-language/",
	"title": "1. Simple grammar to define loop semantics",
	"tags": ["antlr", "kotlin", "parser", "grammar"],
	"categories": [],
	"series": ["Writing a Parser for a Small Language"],
	"description": "",
	"content": "For a long time I've been facinated by parsers and in particularly ANTLR (the parser generator).\nANTLR is a parser generator which makes it simple to define a grammar made of tokens (lexer rules) and a parser rules, and then generate code to parse the defined grammar.\nThere are plenty of other articles explaining parsers, and in particular ANTLR, but I wanted to skip that and move straight into defining my own interpreted language leveraging the code generated by ANTLR.\n TODO: Listener vs Visitor pattern\n Series  Simple grammar to define loop semantics Implementing the parser (in Kotlin) Add variable assignment and interpolation Add branching (if/else)  StupidLang \u0026hellip; is the name of my stupid language. It's not made to be a useful language, but rather a means to learning about ANTLR and the Visitor pattern.\nFor starters, I wanted to be able to implement a loop.\nrepeat 5 { print \u0026quot;hello world\u0026quot;; }; Lexer Rules Lexer rules make the parser grammar a lot easier to define, and improves on the utility of the generated code (you'll end up with objects representing the tokens rather than having to dig out and check strings). More on that later.\nLooking at the example above, I see a number of tokens. In ANTLR grammar (g4) files, tokens must start with a capital letter (ideally complete caps) to differentiate from parser rules which begin with a lower case.\nDecisions:\n Keywords will be tokenized. I want the script to be parsable without whitespace (this makes the parser rules easy to write because we are only concerned with a stream of meaningful tokens)  StupidLangLexer.g4\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18  // Specify that this are the lexer ruleslexergrammarStupidLangLexer;// statement keywordsREPEAT:\u0026#39;repeat\u0026#39;;PRINT:\u0026#39;print\u0026#39;;// TypesNUMBER:[0-9]+;// Special charactersLBRACE:\u0026#39;{\u0026#39;;RBRACE:\u0026#39;}\u0026#39;;SEMICOLON:\u0026#39;;\u0026#39;;DQUOTE:\u0026#39;\u0026#34;\u0026#39;;// Send all whitespace to a hidden channelWS:[\\r\\n\\t ]+-\u0026gt;channel(HIDDEN);  The above seems pretty straight forward. Let's now write some parsing rules.\nParser Rules Parser rules define the actual structure of the langauge, and use tokens from the lexer rules to both the writing and reading of the grammar.\nDecisions:\n Each script file will be interpreted alone and in isolation for now. An empty file is valid.  Using the loop example above, it seems like we start of with a file, which contains zero or more statements.\nWe support two statements so far:\n repeat with two parameters (a number, and a block or closure) print with a string parameter, and a semicolon to indicate the end of the statement.  Note: Typically code blocks (indicated by { and }) do not need a semicolon ; as their end is unambiguous, but the parser rules become a bit more complex so I have made it mandatory. I could infer stataments end with a newline, but remeber, we are hiding whitespace. There are tradeoffs.\nI like to put the entry point rule at the start to make it obvious. In this case file.\nStupidLangParser.g4\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39  // Specify that this are the parser rulesparsergrammarStupidLangParser;// Refer to the lexer rulesoptions{tokenVocab=StupidLangLexer;}// The file contains (or doesn\u0026#39;t contain) statements// EOF is a special token when then end of the token stream is reached.file:statements?EOF;// Statements are one or more statement followed by a terminatorstatements:(statementSEMICOLON)+;// We permit a number of statementsstatement:repeat|print;// Repeat takes two parameters, a number and a code blockrepeat:REPEATtimesLBRACEstatements?RBRACE;// Just a shortcut rule to make sense of the grammar.times:NUMBER;// Print non greedily takes everything between two double quotes// Do you spot the problem?print:PRINTDQUOTE.*?DQUOTE;  Our first problem: Missing whitespaces In trying to make the grammar simple to define, we told the lexer to ignore whitespaces\u0026hellip; but what happens when we want to do print \u0026quot;hello world\u0026quot;? The parser would see the stream of charaters between the DQUOTE tokens as helloworld.\nSo we mostly want to hide whitespaces, but not always\u0026hellip; Hmm, I wish we could jump into a different mode for when we need to parse strings, and not hide whitespaces.\nModes Modes allow us to jump into a different parsing context, for when we need to sometimes apply different lexer rules. This is perfect. We want to remove whitespace in general, except for when we know we are parsing a string (indicated by the DQUOTE token).s\nIn ANTLR, modes are pushed onto, and popped off a stack as the parser takes in the stream of tokens.\nSo, let's revise our lexer grammar:\nStupidLangLexer.g4\n1 2 3 4 5 6 7 8 9 10  // Special characters// ...DQUOTE:\u0026#39;\u0026#34;\u0026#39;-\u0026gt;pushMode(STRING_MODE);// Send all whitespace to a hidden channelWS:[\\r\\n\\t ]+-\u0026gt;channel(HIDDEN);modeSTRING_MODE;S_DQUOTE:\u0026#39;\u0026#34;\u0026#39;-\u0026gt;type(DQUOTE),popMode;CHARACTER:.;  Important: The rule for sending whitespace to a hidden channel must appear before any modes are defined, but after all rules that pushMode into a mode that should have spaces preserved.\nNote: The rule names within each mode must be unique, hence the prefixing. Also notice that as we use type(DQUOTE) to equate the redefined double-quote with the already defined DQUOTE. _Todo: find out exactly what this does, I assume it is so you can simply use the main token inside the parser rules.\nThe stack nature of modes gives us a lot of power. For example, we could allow escaped charaters: print \u0026quot;double quote: \\\u0026quot;\u0026quot;. We could just define some extra lexer rules to take us into a literal parsing mode whenever we see a \\ from string processing mode.\nStupidLangLexer.g4\n1 2 3 4 5 6 7 8  modeSTRING_MODE;S_ESCAPE:\u0026#39;\\\u0026#39; -\u0026gt; pushMode(LITERAL_MODE); S_DQUOTE : \u0026#39;\u0026#34;\u0026#39;-\u0026gt;type(DQUOTE),popMode;CHARACTER:.;modeLITERAL_MODE;LITERAL:.-\u0026gt;popMode;  You could extend this to be able to do things like string interpolation of variables.\nNow we can adjust the parser rule:\nStupidLangParser.g4\n1 2 3 4 5 6 7 8 9 10 11  // ...print:PRINTDQUOTEstringDQUOTE;// Shortcut so we have a named property in the generated codestring:.*?;  Verify Generate and compile the code\n1 2 3  antlr4 StupidLangLexer.g4 antlr4 StupidLangParser.g4 javac StupidLang*.java   Make a file with the stupid script:\n1 2 3 4 5 6 7 8 9 10 11  cat \u0026gt;\u0026gt; /tmp/loop.stupid \u0026lt;\u0026lt;EOF repeat 5 { print \u0026#34;hello world\u0026#34;; }; repeat 3 { print \u0026#34;hi\u0026#34;; }; print \u0026#34;the end\u0026#34;; EOF   Run it against ANTLR's parse tree viewer:\n1  grun StupidLang file -gui \u0026lt; /tmp/loop.stupid    "
},
{
	"uri": "https://nicklarsennz.github.io/tags/antlr/",
	"title": "antlr",
	"tags": [],
	"categories": [],
	"series": [],
	"description": "",
	"content": ""
},
{
	"uri": "https://nicklarsennz.github.io/tags/grammar/",
	"title": "grammar",
	"tags": [],
	"categories": [],
	"series": [],
	"description": "",
	"content": ""
},
{
	"uri": "https://nicklarsennz.github.io/tags/kotlin/",
	"title": "kotlin",
	"tags": [],
	"categories": [],
	"series": [],
	"description": "",
	"content": ""
},
{
	"uri": "https://nicklarsennz.github.io/",
	"title": "NickLarsenNZ",
	"tags": [],
	"categories": [],
	"series": [],
	"description": "",
	"content": ""
},
{
	"uri": "https://nicklarsennz.github.io/tags/parser/",
	"title": "parser",
	"tags": [],
	"categories": [],
	"series": [],
	"description": "",
	"content": ""
},
{
	"uri": "https://nicklarsennz.github.io/posts/",
	"title": "Posts",
	"tags": [],
	"categories": [],
	"series": [],
	"description": "",
	"content": ""
},
{
	"uri": "https://nicklarsennz.github.io/series/",
	"title": "Series",
	"tags": [],
	"categories": [],
	"series": [],
	"description": "",
	"content": ""
},
{
	"uri": "https://nicklarsennz.github.io/tags/",
	"title": "Tags",
	"tags": [],
	"categories": [],
	"series": [],
	"description": "",
	"content": ""
},
{
	"uri": "https://nicklarsennz.github.io/series/writing-a-parser-for-a-small-language/",
	"title": "Writing a Parser for a Small Language",
	"tags": [],
	"categories": [],
	"series": [],
	"description": "",
	"content": ""
},
{
	"uri": "https://nicklarsennz.github.io/categories/",
	"title": "Categories",
	"tags": [],
	"categories": [],
	"series": [],
	"description": "",
	"content": ""
}]